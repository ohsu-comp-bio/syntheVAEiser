#!/usr/bin/env python

import sys
import json
import argparse
import numpy as np
import pandas as pd
import keras
import os

import tensorflow as tf
import tensorflow.compat.v1.keras.backend as K

#hack
tf.compat.v1.disable_eager_execution()


#some global variables....
z_mean_encoded = None
z_log_var_encoded = None
beta = None

class CustomVariationalLayer(tf.keras.layers.Layer):
    """
    Define a custom layer
    """
    def __init__(self, original_dim, **kwargs):
        self.is_placeholder = True
        self.original_dim = original_dim
        super(CustomVariationalLayer, self).__init__(**kwargs)

    def vae_loss(self, x_input, x_decoded):
        reconstruction_loss = self.original_dim * tf.keras.metrics.binary_crossentropy(x_input, x_decoded)
        kl_loss = - 0.5 * K.sum(1 + z_log_var_encoded - K.square(z_mean_encoded) - 
                                K.exp(z_log_var_encoded), axis=-1)
        return K.mean(reconstruction_loss + (K.get_value(beta) * kl_loss))

    def call(self, inputs):
        x = inputs[0]
        x_decoded = inputs[1]
        loss = self.vae_loss(x, x_decoded)
        self.add_loss(loss, inputs=inputs)
        return x


class WarmUpCallback(tf.keras.callbacks.Callback):
    def __init__(self, beta, kappa):
        self.beta = beta
        self.kappa = kappa

    def on_epoch_end(self, epoch, logs={}):
        if K.get_value(self.beta) <= 1:
            K.set_value(self.beta, K.get_value(self.beta) + self.kappa)

def compute_latent(x):
    mu, sigma = x
    batch = K.shape(mu)[0]
    dim = K.shape(mu)[1]
    eps = K.random_normal(shape=(batch,dim), mean=0., stddev=1.0 )
    return mu + K.exp(sigma/2)*eps

def run_train(args):
    global z_mean_encoded
    global z_log_var_encoded
    global beta

    df = None
    for y in args.inputs:
        x = pd.read_csv(y, sep="\t", index_col=0)
        if df is None:
            df = x
        else:
            df = pd.concat([df, x])

    features = list( i for i in df.columns if i not in args.exclude )
    feature_dim = len(features)

    train_matrix = df[features]

    latent_dim = args.latent_dim
    learning_rate = args.learning_rate



    encoder_inputs = tf.keras.Input(shape=(feature_dim,))
    z_mean_dense_linear = tf.keras.layers.Dense(
        latent_dim, kernel_initializer='glorot_uniform', name="encoder_1")(encoder_inputs)
    z_mean_dense_batchnorm = tf.keras.layers.BatchNormalization()(z_mean_dense_linear)
    z_mean_encoded = tf.keras.layers.Activation('relu')(z_mean_dense_batchnorm)

    z_log_var_dense_linear = tf.keras.layers.Dense(
        latent_dim, kernel_initializer='glorot_uniform', name="encoder_2")(encoder_inputs)
    z_log_var_dense_batchnorm = tf.keras.layers.BatchNormalization()(z_log_var_dense_linear)
    z_log_var_encoded = tf.keras.layers.Activation('relu')(z_log_var_dense_batchnorm)

    latent_space = tf.keras.layers.Lambda(
        compute_latent, output_shape=(
            latent_dim,), name="latent_space")([z_mean_encoded, z_log_var_encoded])

    decoder_to_reconstruct = tf.keras.layers.Dense(
        feature_dim, kernel_initializer='glorot_uniform', activation='sigmoid')
    decoder_outputs = decoder_to_reconstruct(latent_space)


    kappa = 1
    beta = K.variable(0)

    adam = tf.keras.optimizers.Adam(learning_rate=learning_rate)
    vae_layer = CustomVariationalLayer(feature_dim)([encoder_inputs, decoder_outputs])
    vae = tf.keras.models.Model(encoder_inputs, vae_layer)
    vae.compile(optimizer=adam, loss=None, loss_weights=[beta])

    pre_train_epochs = args.epochs
    batch_size = args.batch_size

    history = vae.fit(train_matrix,
                epochs=pre_train_epochs,
                batch_size=batch_size,
                shuffle=True,
                callbacks=[WarmUpCallback(beta, kappa)],
                #verbose=0
    )
               
    # Model to compress input
    encoder = tf.keras.models.Model(encoder_inputs, z_mean_encoded)

    decoder_input = tf.keras.Input(shape=(latent_dim, ))  # can generate from any sampled z vector
    _x_decoded_mean = decoder_to_reconstruct(decoder_input)
    decoder = tf.keras.models.Model(decoder_input, _x_decoded_mean)

    with open(args.out + ".info", "tw") as handle:
        handle.write(json.dumps({
            "features" : features
        }))
            
    encoder.save(args.out + ".encoder")
    decoder.save(args.out + ".decoder")

 
    
def synth_latent_3(args,latent_object, synth_index_name):
    synth_in_count = 3
    synth_ndx_strt = 0
    synth_full_frame = pd.DataFrame(columns = latent_object.columns)

    for subtype in sorted(latent_object.Labels.unique()):  # here is the latent object in memory, from ONLY the trn object
        print(subtype)
        sub = latent_object[latent_object.Labels == subtype]
        #print(args.num_sample_gen)
        synth_index = ['SYNTH-' + synth_index_name + '-' + jtem for jtem in [str(
            item).zfill(5) for item in list(range(synth_ndx_strt,
                                                  args.num_sample_gen + synth_ndx_strt))]]
        synth_sub_frame = pd.DataFrame(index = synth_index)
        synth_sub_frame.insert(0, 'Labels', sub.Labels[0])

        synth_dict = {}
        for synth_sample in synth_sub_frame.index:
            input_sample_set = sub.sample(synth_in_count)
            new_samp_vec = []
            for col in input_sample_set.iloc[:, 1:]:
                vals_inpt = input_sample_set.loc[:, col] # latent feature VALUES (not validation)
                choosen_val = vals_inpt.sample(1)
                new_samp_vec.append(choosen_val.values[0])

            synth_dict[synth_sample] = new_samp_vec
        synth_sub_frame = pd.concat([synth_sub_frame, pd.DataFrame(synth_dict).T], axis = 1)

        synth_full_frame = pd.concat(
            [synth_full_frame, synth_sub_frame], axis = 0) 

        synth_ndx_strt = synth_ndx_strt + args.num_sample_gen
    print('Synthetic from latent function done, '+str(args.num_sample_gen)+' samples generated for each subtype')
    return(synth_full_frame)


#./synthesis gen data/BRCA.tsv --num-sample-gen 250 
def run_gen(args):
    #load models
    decoder = keras.models.load_model(args.decoder + ".decoder")
    encoder = keras.models.load_model(args.encoder + ".encoder")
    train_size =args.train_size

    #for each input tsv generate synthetic data
    for elem in args.inputs:
        #print("VLAUE OF ARGS",args.inputs[args.inputs.index(elem)])

        input = pd.read_csv(args.inputs[args.inputs.index(elem)],sep='\t',index_col = 0)
        train_sample = input.sample(train_size)
        Labels = input["Labels"]

        decoded = pd.DataFrame(decoder.predict(encoder.predict(input.iloc[:, 1:])),
                                index = input.index, columns = input.iloc[:, 1:].columns)

        latent_object = pd.DataFrame(encoder.predict(input.iloc[:, 1:]),
                        index=input.index)
        
        latent_object.index.name = train_sample.index.name

        latent_object = pd.concat( [pd.DataFrame(Labels), latent_object] , axis =1)
        decoded_labeled = pd.concat( [pd.DataFrame(Labels), decoded] , axis =1)

        synth_full_frame = synth_latent_3(args,latent_object, input.index.name)

        synth_lat_dec = pd.concat([synth_full_frame.iloc[:, 0],
                        pd.DataFrame(decoder.predict(synth_full_frame.iloc[:, 1:]),
                                        index = synth_full_frame.index)], axis = 1)
        
        synth_lat_dec.columns = train_sample.columns

        #  args.inputs[args.inputs.index(elem)] this would save in the same directory as the input tsv
        #optional file path location to store models 

        synth_lat_dec.to_csv(args.out + input.index.name  +  '_synthetic_data.tsv', sep = '\t')
        print(args.out + input.index.name  +  '_synthetic_data.tsv Generated')

        decoded_labeled.to_csv(args.out + input.index.name  + '_decoded_labeled.tsv', sep = '\t')
        print(args.out+ input.index.name  +  '_decoded_labeled.tsv Generated')



if __name__ == "__main__":
    parser = argparse.ArgumentParser(
                    prog = 'Synthesis',
                    description = 'Generate Synthetic samples')
    
    subparsers = parser.add_subparsers(title="subcommand")

    train_parser = subparsers.add_parser('train')
    train_parser.set_defaults(func=run_train)

    train_parser.add_argument("inputs", nargs="+")
    train_parser.add_argument("--latent-dim", type=int, default=50)
    train_parser.add_argument("--learning-rate", type=float, default=0.0005)
    train_parser.add_argument("--batch-size", type=int, default=50)
    train_parser.add_argument("--epochs", type=int, default=4)
    train_parser.add_argument("-e", "--exclude", nargs="*", default=[])
    train_parser.add_argument("-o", "--out", default="model")
    
    train_parser = subparsers.add_parser('gen')
    train_parser.set_defaults(func=run_gen)

    train_parser.add_argument("inputs", nargs="+")
    train_parser.add_argument("-enc", "--encoder", default="model")
    train_parser.add_argument("-dec", "--decoder", default="model")
    train_parser.add_argument("-tsize","--train-size",type=int, default=40)
    train_parser.add_argument("-ngen","--num-sample-gen",type=int, default=200)
    train_parser.add_argument("-o", "--out", default="gen")


    args = parser.parse_args()

    if not hasattr(args, "func"):
        parser.print_help(sys.stderr)
        sys.exit(1)

    func = args.func
    e = func(args)
    sys.exit(e)